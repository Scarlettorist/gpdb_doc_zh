---
title: 在对象存储中读写Parquet数据
---

<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->

PXF 对象存储连接器支持读写Parquet格式数据。 本节描述了如何使用PXF访问对象存储中的Parquet格式数据， 包括创建和查询引用对象存储中Parquet文件的外部表。

<div class="note">PXF Parquet写入支持是一个Beta功能。</div>

**注意**: 从对象存储访问Parquet格式数据与访问HDFS中的Parquet格式数据非常相似。 本主题标识了读取对象存储所需的特定信息，并在通用信息的位置链接到 [PXF HDFS Parquet 文档](hdfs_parquet.html) 。

## <a id="prereq"></a>先决条件

在您尝试从对象存储中读取数据前，确保已满足PXF 对象存储[先决条件](access_objstore.html#objstore_prereq) 。


## <a id="datatype_map"></a>数据类型映射

有关Greenplum数据库和Parquet数据类型之间映射的说明，请参阅 [数据类型映射](hdfs_parquet.html#datatype_map) 。

## <a id="profile_cet"></a>创建外部表

PXF `<objstore>:parquet` 配置文件支持读取和写入Parquet格式数据。 PXF 支持以下 `<objstore>` 配置前缀：

| 对象存储  | 配置前缀 |
|-------|-------------------------------------|
| Azure Blob Storage   | wasbs |
| Azure Data Lake    | adl |
| Google Cloud Storage    | gs |
| Minio    | s3 |
| S3    | s3 |


使用以下语法创建引用S3目录的Greenplum数据库外部表。 当您将记录插入可写外部表中时，您插入的数据块将写入指定目录中一个或多个文件。

``` sql
CREATE [WRITABLE] EXTERNAL TABLE <table_name>
    ( <column_name> <data_type> [, ...] | LIKE <other_table> )
LOCATION ('pxf://<path-to-dir>
    ?PROFILE=<objstore>:parquet[&SERVER=<server_name>][&<custom-option>=<value>[...]]')
FORMAT 'CUSTOM' (FORMATTER='pxfwritable_import'|'pxfwritable_export');
[DISTRIBUTED BY (<column_name> [, ... ] ) | DISTRIBUTED RANDOMLY];
```

[CREATE EXTERNAL TABLE](../ref_guide/sql_commands/CREATE_EXTERNAL_TABLE.html)命令中使用的特定关键字和值见下表中描述。

| 关键字  | 值 |
|-------|-------------------------------------|
| \<path&#8209;to&#8209;dir\>    | 对象存储中文件或目录的绝对路径 |
| PROFILE=\<objstore\>:parquet    | `PROFILE` 必须指定为特定的对象存储。例如，`s3:parquet` |
| SERVER=\<server_name\>    | PXF用于访问数据的命名服务器配置。可选的; 如果未指定，PXF将使用`default`服务器。 |
| \<custom&#8209;option\>=\<value\> | 特定于Parquet的自定义选项描述见 [PXF HDFS Parquet 文档](hdfs_parquet.html#customopts) |
| FORMAT 'CUSTOM' | 使用`FORMAT` '`CUSTOM`'时指定`(FORMATTER='pxfwritable_export')` (写入) 或 `(FORMATTER='pxfwritable_import')` (读取) |
| DISTRIBUTED BY    | 如果您计划将现有Greenplum数据库表中的数据加载到可写外部表，考虑在可写外部表上使用与Greenplum表相同的分布策略或\<字段名\>。 这样做可以避免数据加载操作中segment节点间额外的数据移动。 |

如果要访问S3 对象存储，则可以如 [覆盖S3服务配置](access_objstore.html#s3_override) 中所述直接在 `CREATE EXTERNAL TABLE` 命令中提供S3凭据。
如果要访问S3对象存储库：
- 您可以通过`CREATE EXTERNAL TABLE`命令中的自定义选项提供S3凭据，如[用DDL覆盖S3服务器配置](access_s3.html#s3_override)中所述。
- 如果您正在从S3读取Parquet数据，则可以指示PXF使用S3 Select Amazon服务检索数据。 有关用于此目的的PXF自定义选项的更多信息，请参考[使用Amazon S3选择服务](access_s3.html#s3_select)。

## <a id="example"></a> 示例

有关Parquet 读取/写入的示例，请参阅PXF HDFS Parquet 文档中的 [示例](hdfs_parquet.html#parquet_write) 。 在对象存储中运行示例，必要的修改如下：

- 使用上述的 `CREATE EXTERNAL TABLE` 语法和 `LOCATION` 关键字及设置。例如， 假设您的服务名为 `s3srvcfg` ：

    ``` sql
    CREATE WRITABLE EXTERNAL TABLE pxf_tbl_parquet_s3 (location text, month text, number_of_orders int, total_sales double precision)
      LOCATION ('pxf://BUCKET/pxf_examples/pxf_parquet?PROFILE=s3:parquet&SERVER=s3srvcfg')
    FORMAT 'CUSTOM' (FORMATTER='pxfwritable_export');
    ```

- 使用上述的 `CREATE EXTERNAL TABLE` 语法和 `LOCATION` 关键字及设置。例如， 假设您的服务名为 `s3srvcfg` ：

    ``` sql
    CREATE EXTERNAL TABLE read_pxf_parquet_s3(location text, month text, number_of_orders int, total_sales double precision)
      LOCATION ('pxf://BUCKET/pxf_examples/pxf_parquet?PROFILE=s3:parquet&SERVER=s3srvcfg')
    FORMAT 'CUSTOM' (FORMATTER='pxfwritable_import');
    ```

